{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617dcd89",
   "metadata": {},
   "source": [
    "# Some Object Recognizers\n",
    "Source of some examples: https://github.com/chewbacca89/OpenCV-with-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a list of images side by side\n",
    "def preview(imgs, size=22, xlim=None, ylim=None):\n",
    "    fig, axes = plt.subplots(1, len(imgs), figsize=(size, size))\n",
    "    \n",
    "    # if there is only one subplot, axes is not list\n",
    "    # therefore, we make it a list\n",
    "    if(len(imgs) == 1):\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        img = imgs[i]\n",
    "        \n",
    "        # zoom into image if limits are set\n",
    "        if(xlim is not None):\n",
    "            axes[i].set_xlim(xlim)\n",
    "        if(ylim is not None):\n",
    "            axes[i].set_ylim(ylim)\n",
    "            \n",
    "        # convert image to RGB if it is not grayscale\n",
    "        if(len(img.shape) > 2):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[i].imshow(img)\n",
    "        else:\n",
    "            axes[i].imshow(img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d19e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [12, 8]\n",
    "def show(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def showg(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "def showb(img):\n",
    "    plt.imshow(img, cmap='Greys', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a655ce",
   "metadata": {},
   "source": [
    "# Marker Detection\n",
    "\n",
    "If in doubt: use [ArUco](https://www.uco.es/investiga/grupos/ava/node/26) markers:\n",
    "\n",
    "- developed at Universidad de CÃ³rdoba\n",
    "- simple, fast (C++)\n",
    "- partially supported out-of-the-box in OpenCV (cv2.aruco)\n",
    "- important: choose distinct markers (Hamming distance large)\n",
    "\n",
    "In-depth tutorial: https://www.pyimagesearch.com/2020/12/21/detecting-aruco-markers-with-opencv-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/lego_coins_aruco_perspective.jpg\")\n",
    "image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC )\n",
    "show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29618a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners, marker_ids, unidentified = cv2.aruco.detectMarkers(image, dic)\n",
    "print(marker_ids)\n",
    "print(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected = cv2.aruco.drawDetectedMarkers(image, corners, marker_ids)\n",
    "show(detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778b413",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5314cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "beach = cv2.imread('images/WaldoBeach.jpg')\n",
    "show(beach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff078f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "waldo = cv2.imread('images/waldo.jpg')\n",
    "show(waldo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01daf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_gray = cv2.cvtColor(beach, cv2.COLOR_BGR2GRAY)\n",
    "waldo_gray = cv2.cvtColor(waldo, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "result = cv2.matchTemplate(beach_gray, waldo_gray, cv2.TM_CCOEFF)\n",
    "show(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.interp(result, (result.min(), result.max()), (0, 255)).astype(int)\n",
    "#result\n",
    "showg(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "print(min_val, max_val, min_loc, max_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_left = max_loc\n",
    "bottom_right = (max_loc[0] + 50, max_loc[1] + 50)\n",
    "found = cv2.rectangle(beach, top_left, bottom_right, (0,0,255), 5)\n",
    "show(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin = top_left\n",
    "xmax, ymax = bottom_right\n",
    "cropped = found[ymin:ymax,xmin:xmax]\n",
    "show(cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8cc2c-7f16-45f5-bdda-1f9825ff569c",
   "metadata": {},
   "source": [
    "**Warning:** this does not work reliably!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c4b99",
   "metadata": {},
   "source": [
    "# Face Recognition using Haar Cascades\n",
    "\n",
    "In-depth tutorial: https://www.pyimagesearch.com/2021/04/12/opencv-haar-cascades/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a5696-1337-4696-9e25-1010732e6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python  # for Haar cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04820862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We point OpenCV's CascadeClassifier function to where our \n",
    "# classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "image = cv2.imread('images/Hillary.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if len(faces) == 0:\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    image = cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "\n",
    "show(image)\n",
    "# see also: cvlib.detect_face()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5fbfb",
   "metadata": {},
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "- OpenCV supports various DNNs\n",
    "- nice wrapper: https://www.cvlib.net/\n",
    "- if in doubt: [YOLO](https://pjreddie.com/darknet/yolo/)\n",
    "\n",
    "Image: https://commons.wikimedia.org/wiki/File:Traffic_Jam_in_Nairobi.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires cvlib, OpenCV tensorflow and CUDA support (libcudart.so.11.0 on Linux)\n",
    "# downloads required data on first run\n",
    "import cvlib as cvl\n",
    "from cvlib.object_detection import draw_bbox\n",
    "\n",
    "img = cv2.imread(\"images/food.jpg\")\n",
    "bbox, label, conf = cvl.detect_common_objects(img, confidence=0.3, model='yolov3-tiny')\n",
    "print(label)\n",
    "output_image = draw_bbox(img, bbox, label, conf)\n",
    "show(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcefa275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see also: https://jacquesmattheij.com/sorting-two-metric-tons-of-lego/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61788841",
   "metadata": {},
   "source": [
    "# Our Task\n",
    "\n",
    "Detect and identify lego pieces and coins in the example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fade0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/lego_coins_aruco.jpg\")\n",
    "image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC )\n",
    "show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9465a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
